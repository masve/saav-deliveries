{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather and Motor Vehicle Collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil.rrule import rrule, DAILY\n",
    "from __future__ import division\n",
    "import geoplotlib as glp\n",
    "from geoplotlib.utils import BoundingBox, DataAccessObject\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date = date(2012, 7, 1)\n",
    "end_date = date(2016, 2, 29)\n",
    "\n",
    "# data = pd.DataFrame()\n",
    "frames = []\n",
    "url_template = 'https://www.wunderground.com/history/airport/KJFK/%s/%s/%s/DailyHistory.html?req_city=New+York&req_state=NY&req_statename=New+York&reqdb.zip=10001&reqdb.magic=4&reqdb.wmo=99999&format=1.csv'\n",
    "\n",
    "month = \"\"\n",
    "\n",
    "for dt in rrule(DAILY, dtstart=start_date, until=end_date):\n",
    "    if (month != dt.strftime(\"%m\")):\n",
    "        month = dt.strftime(\"%m\")\n",
    "        print 'Downloading to memory: ' + dt.strftime(\"%Y-%m\")    \n",
    "    frames.append(pd.read_csv(url_template % (dt.strftime(\"%Y\"),dt.strftime(\"%m\"), dt.strftime(\"%d\"))))\n",
    "\n",
    "print \"Saving data to csv...\"\n",
    "data = pd.concat(frames)\n",
    "data.to_csv('weather_data_nyc_kjfk.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the weather dataset\n",
    "### Convert weather DateUTC to local time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "weather = pd.read_csv('datasets/weather_data_nyc_kjfk_clean.csv')\n",
    "\n",
    "def UTCtoActual(utcDate):\n",
    "    from_zone = tz.gettz('UTC')\n",
    "    to_zone = tz.gettz('America/New_York')\n",
    "    \n",
    "    utc = datetime.strptime(utcDate.DateUTC, '%Y-%m-%d %H:%M:%S')\\\n",
    "                  .replace(tzinfo=from_zone)\\\n",
    "                  .astimezone(to_zone)\n",
    "    s = pd.Series([utc.year, utc.month, utc.day, utc.hour])\n",
    "    s.columns = ['Year', 'Month', 'Day', 'Hour']\n",
    "    return s\n",
    "    \n",
    "#weather['DateActual'] = weather.DateUTC.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather[['Year', 'Month', 'Day', 'Hour']] = weather.apply(UTCtoActual, axis=1)\n",
    "weather.to_csv('datasets/weather_data_nyc_kjfk_clean2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge weather and NYPD MVC datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "incidents = pd.read_csv('datasets/NYPD_Motor_Vehicle_Collisions.csv')\n",
    "weather = pd.read_csv('datasets/weather_data_nyc_kjfk_clean2.csv')\n",
    "weather.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather[(weather.Year == 2015) & (weather.Month == 11) & (weather.Day == 27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features0 = ['Conditions', 'TemperatureC']\n",
    "features = ['Conditions', \\\n",
    "            'Precipitationmm', \\\n",
    "            'TemperatureC', 'VisibilityKm']\n",
    "\n",
    "def lookup_weather2(year, month, day, hour):\n",
    "    w = weather[(weather.Year == year) & (weather.Month == month) & (weather.Day == day) & (weather.Hour == hour)]\n",
    "    return w\n",
    "\n",
    "def lookup_weather(date, time):\n",
    "    month = int(date.split('/')[0])\n",
    "    day = int(date.split('/')[1])\n",
    "    year = int(date.split('/')[2])\n",
    "    hour = int(time.split(':')[0])\n",
    "    d = lookup_weather2(year, month, day, hour).head(1)\n",
    "    if (d.empty):\n",
    "        dt_back = datetime.datetime(year, month, day, hour) - datetime.timedelta(hours=1)\n",
    "        dt_forward = datetime.datetime(year, month, day, hour) + datetime.timedelta(hours=1)\n",
    "        \n",
    "        d_back = lookup_weather2(dt_back.year, dt_back.month, dt_back.day, dt_back.hour)\n",
    "        if (not d_back.empty): return d_back\n",
    "        \n",
    "        d_forward = lookup_weather2(dt_forward.year, dt_forward.month, dt_forward.day, dt_forward.hour)\n",
    "        if (not d_forward.empty): return d_forward\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "def merge_weather(incident):\n",
    "    date = incident.DATE\n",
    "    time = incident.TIME\n",
    "    #print \"0\"\n",
    "    w = lookup_weather(date, time)\n",
    "    #[unnamed, condition, dateUTC, Dew, Events, Gust, Humidity,Precipitationmm,Sea_Level_PressurehPa, TemperatureC] = w.values[0]\n",
    "\n",
    "    #print \"1\"\n",
    "    try:\n",
    "        #print \"2\"\n",
    "        #print w\n",
    "        con = \"-\"\n",
    "        temp = \"-\"\n",
    "        rainmm = \"-\"\n",
    "        viskm = \"-\"\n",
    "        #print \"2.5\"\n",
    "        if (not pd.isnull(w['Conditions'].iloc[0])):\n",
    "            con = w['Conditions'].iloc[0]\n",
    "        if (not pd.isnull(w['TemperatureC'].iloc[0])):\n",
    "            temp = w['TemperatureC'].iloc[0]\n",
    "        if (not pd.isnull(w['Precipitationmm'].iloc[0])):\n",
    "            rainmm = w['Precipitationmm'].iloc[0]\n",
    "        if (not pd.isnull(w['VisibilityKm'].iloc[0])):\n",
    "            viskm = w['VisibilityKm'].iloc[0]\n",
    "            \n",
    "        #print 'con %s, temp %s, rainmm %s, viskm %s' % (con, temp, rainmm, viskm)\n",
    "        \n",
    "        #print \"2.75\"\n",
    "        s = pd.Series([con, rainmm, temp, viskm])\n",
    "        #print \"3\"\n",
    "        #print str(len(w.values[0]))\n",
    "        #s = pd.Series(w.values[0])\n",
    "        #s = pd.Series([w['Conditions'].iloc[0], w['Dew PointC'].iloc[0], w['Gust SpeedKm/h'].iloc[0]])\n",
    "\n",
    "        #s.columns = features\n",
    "        return s\n",
    "    except:\n",
    "        #print \"4\"\n",
    "        print date + \"x\" + time\n",
    "        s = pd.Series([None,None,None,None])\n",
    "        #s = pd.Series([\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "        #s = pd.Series([])\n",
    "        #s.columns = features\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#lookup_weather2(2016, 2, 14, 7)\n",
    "#lookup_weather('03/14/2016', '3:27').values[0]\n",
    "#[unnamed, condition, dateUTC, Dew, Events, Gust, Humidity,Precipitationmm,Sea_Level_PressurehPa, TemperatureC] = lookup_weather('01/27/2016', '3:27').values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Applying weather data to incidents...\"\n",
    "incidents[features] = incidents[incidents.DATE.str.split('/').str.get(2) != '2016'].apply(merge_weather, axis=1)\n",
    "print \"Saving weather in-riched incident data...\"\n",
    "incidents.to_csv('datasets/NYPD_Motor_Vehicle_Collisions_weather4.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incidents[incidents.DATE.str.split('/').str.get(2) == '2016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some nice data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "incidents = pd.read_csv('datasets/NYPD_Motor_Vehicle_Collisions_weather4.csv')\n",
    "# Filter 2016 incidents\n",
    "incidents = incidents[(incidents.DATE.str.split('/').str.get(2) != '2016') \n",
    "                      & (pd.notnull(incidents.Conditions))\n",
    "                      & (incidents.Conditions != \"Mist\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution of incidents by weather conditions\n",
    "ys = []\n",
    "xs = []\n",
    "\n",
    "for c in incidents.Conditions.unique():\n",
    "    mask = (incidents.Conditions == c)\n",
    "    filtered_incidents = incidents[mask]\n",
    "    ys.append(len(filtered_incidents.index))\n",
    "    xs.append(c)\n",
    "\n",
    "df = pd.DataFrame(pd.Series(ys, index=xs, name=\"Incidents by weather conditions\").sort_values())\n",
    "df.plot(kind='barh', figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now lets try to find out if there are any condition that causes more incidents than others. We do this by plotting out heatmaps to get an idea of the distributions in the NYC area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_zip_weather(condition, data):\n",
    "    ys = []\n",
    "    xs = []\n",
    "\n",
    "    for z in data['ZIP CODE'].unique():\n",
    "        mask = (data['ZIP CODE'] == z)\n",
    "        filtered_incidents = data[mask]\n",
    "        ys.append(len(filtered_incidents.index))\n",
    "        xs.append(z)\n",
    "\n",
    "    df = pd.DataFrame(pd.Series(ys, index=xs, name=\"%s incidents by zip code\" % condition).sort_values())\n",
    "    df.plot(kind='barh', figsize=(8,32))\n",
    "\n",
    "def draw_kde(data):\n",
    "    bbox = BoundingBox(north=data.LATITUDE.max()-0.055,\\\n",
    "                       west=data.LONGITUDE.min()+0.055,\\\n",
    "                       south=data.LATITUDE.min()-0.055,\\\n",
    "                       east=data.LONGITUDE.max()+0.055)\n",
    "\n",
    "    coords = {'lat': data.LATITUDE.values.tolist(), 'lon': data.LONGITUDE.values.tolist()}\n",
    "    \n",
    "    glp.kde(coords, bw=5, cut_below=1e-4)\n",
    "    glp.set_bbox(bbox)\n",
    "    glp.inline()\n",
    "    \n",
    "def plot_stuff(conditions, data):\n",
    "    print \"%s conditions\" % conditions \n",
    "    plot_zip_weather(conditions, data)\n",
    "    draw_kde(data)\n",
    "\n",
    "snowy = incidents[incidents['Conditions'].str.contains('Snow')]\n",
    "rainy = incidents[incidents['Conditions'].str.contains('Rain')]\n",
    "clear = incidents[incidents['Conditions'].str.contains('Clear')]\n",
    "cloudy = incidents[(incidents['Conditions'].str.contains('Cloud')) | (incidents['Conditions'].str.contains('Overcast'))]\n",
    "haze = incidents[incidents['Conditions'].str.contains('Haze')]\n",
    "plot_stuff(\"Snowy\", snowy)\n",
    "plot_stuff(\"Rainy\", rainy)\n",
    "plot_stuff(\"Clear\", clear)\n",
    "plot_stuff(\"Cloudy\", cloudy)\n",
    "plot_stuff(\"Hazy\", haze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the ratio between conditions that resulted in an incident. Borough level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "ConditionIncidentCounter = Counter(incidents.Conditions.values)\n",
    "\n",
    "p_incident = {}\n",
    "for k,v in ConditionIncidentCounter.most_common():\n",
    "    p_incident[k] = v/len(incidents)\n",
    "\n",
    "p_incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What is the probability of an incident based on the weather condition?\n",
    "# Normalize incidents based on the conditions.\n",
    "\n",
    "from collections import Counter\n",
    "ConditionIncidentCounter = Counter(incidents.Conditions.values)\n",
    "\n",
    "p_incident = {}\n",
    "for k,v in ConditionIncidentCounter.most_common():\n",
    "    p_incident[k] = v/len(incidents)\n",
    "\n",
    "p_incident\n",
    "\n",
    "# Do the same again but for individual areas of NYC\n",
    "p_incident_district = {}\n",
    "l = len(incidents)\n",
    "for district in incidents[pd.notnull(incidents.BOROUGH)].BOROUGH.unique():\n",
    "    filtered = incidents[incidents.BOROUGH == district]\n",
    "    counter = Counter(filtered.Conditions.values)\n",
    "    p_incident_district[district] = {}\n",
    "    for k,v in counter.most_common():\n",
    "            p_incident_district[district][k] = v / len(list(counter.elements()));\n",
    "            \n",
    "p_incident_district\n",
    "\n",
    "# Are there any areas in NYC that experience incidents based \n",
    "#  on a condition unusually higher or lower compared to other areas?\n",
    "# Calculate the ratio of incidents based on the condition.\n",
    "def calcRatioForDistrict(districtCounter, overAllCounter, district):\n",
    "    ys = []\n",
    "    xs = []\n",
    "    for con in incidents.Conditions.unique():\n",
    "        ys.append(districtCounter[con] / overAllCounter[con])\n",
    "        xs.append(con)\n",
    "    return pd.Series(ys, index=xs)\n",
    "    \n",
    "series = {}\n",
    "for b in incidents[pd.notnull(incidents.BOROUGH)].BOROUGH.unique():\n",
    "    series[b] = calcRatioForDistrict(p_incident_district[b], p_incident, b)\n",
    "\n",
    "df = pd.DataFrame(series)\n",
    "df.plot(kind=\"bar\", subplots=True, figsize=(14,14),layout=(7,2), legend=False,sharey=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try to look at zip codes in Brooklyn only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What is the probability of an incident based on the weather condition?\n",
    "# Normalize incidents based on the conditions.\n",
    "\n",
    "from collections import Counter\n",
    "borough = incidents[incidents.BOROUGH == 'MANHATTAN']\n",
    "ConditionIncidentCounter = Counter(borough.Conditions.values)\n",
    "\n",
    "p_incident = {}\n",
    "for k,v in ConditionIncidentCounter.most_common():\n",
    "    p_incident[k] = v/len(borough)\n",
    "\n",
    "p_incident\n",
    "\n",
    "# Do the same again but for individual areas of NYC\n",
    "p_incident_borough_zip = {}\n",
    "l = len(borough)\n",
    "for z in borough[pd.notnull(incidents['ZIP CODE'])]['ZIP CODE'].unique():\n",
    "    filtered = borough[incidents['ZIP CODE'] == z]\n",
    "    counter = Counter(filtered.Conditions.values)\n",
    "#     z = str(z).split(\".\")[0]\n",
    "    p_incident_borough_zip[z] = {}\n",
    "    for k,v in counter.most_common():\n",
    "        p_incident_borough_zip[z][k] = v / len(list(counter.elements()));\n",
    "            \n",
    "p_incident_borough_zip\n",
    "\n",
    "# Are there any areas in NYC that experience incidents based \n",
    "#  on a condition unusually higher or lower compared to other areas?\n",
    "# Calculate the ratio of incidents based on the condition.\n",
    "def calcRatioForDistrict(districtCounter, overAllCounter, district):\n",
    "    ys = []\n",
    "    xs = []\n",
    "    for con in incidents.Conditions.unique():\n",
    "        if (con in districtCounter):\n",
    "            ys.append(districtCounter[con] / overAllCounter[con])\n",
    "        else:\n",
    "            ys.append(0)\n",
    "        xs.append(con)\n",
    "    return pd.Series(ys, index=xs)\n",
    "    \n",
    "series = {}\n",
    "for z in borough[pd.notnull(incidents['ZIP CODE'])]['ZIP CODE'].unique():\n",
    "    series[z] = calcRatioForDistrict(p_incident_borough_zip[z], p_incident, b)\n",
    "\n",
    "df = pd.DataFrame(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\", subplots=True, figsize=(14,100), layout=(50,2), legend=False, sharey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worst_day = incidents.DATE.value_counts().index[0]\n",
    "worst_day_count = incidents.DATE.value_counts()[0]\n",
    "\n",
    "incidents[incidents.DATE == worst_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
